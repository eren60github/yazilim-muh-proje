{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN2yQCTzSWJ8+qOYLBKVyVo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eren60github/yazilim-muh-proje/blob/main/Untitled4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.Problem Tanımı:\n",
        "Bir e-ticaret müşteri hizmetleri botu, müşteri sorularını anlamalı, müşteri memnuniyetini değerlendirmeli ve uygun yanıtları sunmalıdır. Bu bot, aşağıdaki adımları gerçekleştirmelidir:\n",
        "\n",
        "Girdi ve Çıktılar:\n",
        "\n",
        "Girdi: Müşterinin sorduğu soru ve müşteri memnuniyetini belirtmek için \"memnun\" veya \"memnun değil\" ifadesi.\n",
        "\n",
        "Çıktı: Müşteriye yanıt olarak sunulan metin ve müşteri memnuniyetinin kümelendirilmesi.\n",
        "\n",
        "Sorgular ve Yorumlar:\n",
        "\n",
        "Müşteri soruları genel olarak sipariş durumu, iade politikası, ödeme yöntemleri, gönderim süreleri ve sıkça sorulan diğer sorulara odaklanmalıdır.\n",
        "Müşteri memnuniyeti “memnun” veya “memnun değil” olarak değerlendirilmelidir.\n",
        "\n",
        "Kullanılan Model ve Yöntemler:\n",
        "\n",
        "GPT-2 dil modelini kullanarak müşteri sorularına yanıt üretme.\n",
        "Modeli eğitmek ve optimize etmek için veritabanından müşteri soruları ve yanıtları kullanmak.\n",
        "KMeans kümeleme yöntemi ile müşteri memnuniyeti değerlendirmesini sınıflandırmak.\n",
        "\n",
        "Örnek Problem:\n",
        "\n",
        "Müşteri, \"Siparişimi nasıl iptal edebilirim?\" sorusunu sorar ve müşteri memnuniyetini belirtir.\n",
        "GPT-2 tabanlı müşteri hizmetleri botu, soruyu yanıtlar ve müşteri memnuniyetini değerlendirilir ve sınıflandırılır.\n",
        "Veritabanındaki müşteri yorumları güncellenir ve model yeniden eğitilir."
      ],
      "metadata": {
        "id": "GRF1QURkOQtv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.proje ekibinin katkıları;\n",
        "\n",
        "\n",
        "Özgün:\n",
        "Övül, bu projede yapay zeka ve doğal dil işleme konularındaki ve rapor yazımında yardım etti.  Veri ön işleme tekniklerini kullanarak müşteri soruları ve yanıtlarının model tarafından doğru bir şekilde işlenmesini sağladı.\n",
        "\n",
        "Eren:\n",
        "Eren, modelin müşteri soruları ve yanıtlarını etkili bir şekilde anlayıp işleyebilmesini ve rapora katkı sağladı. Eğitim sürecini yönetirken veri işleme tekniklerini kullanarak modelin doğru ve anlamlı yanıtlar üretmesine katkıda bulundu.\n",
        "\n",
        "Kenan:\n",
        "Kenan, müşteri odaklı tasarım konusunda yardım etti. Proje boyunca müşteri sorularının ve yanıtlarının kullanıcı deneyimine olan etkisini göz önünde bulundurdu. Modelin müşteri memnuniyetini değerlendiren  kümeleme algoritmasının doğru bir şekilde uygulanmasına destek oldu."
      ],
      "metadata": {
        "id": "R9nylwDdOkVl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.Bu projede kullanılan çözüm yöntemi;\n",
        "müşteri hizmetleri botu için dil işleme ve müşteri memnuniyet değerlendirmesi konusunda çeşitli tekniklerin bir araya getirilmesi:\n",
        "\n",
        "Müşteri Soruları ve Yanıtlarının Toplanması:\n",
        "Müşteri soruları ve yanıtları, müşteri hizmetleri botunun geliştirilmesi ve eğitilmesi için kullanılır. Bu sorular ve yanıtlar, modelin doğru ve anlamlı yanıtlar üretebilmesi için kullanılır.\n",
        "\n",
        "Veri Ön İşleme ve Analiz:\n",
        "Müşteri soruları ve yanıtları üzerinde veri ön işleme işlemleri yapılır. Bu işlem, metin temizleme, tokenizasyon, padleme ve veri dönüşümü gibi adımları içerir. Bu adımlar, modelin doğru şekilde işlenmesini ve yanıt vermesini sağlar.\n",
        "\n",
        "Dil Modelinin Eğitimi:\n",
        "Dil modeli, müşteri soruları ve yanıtları üzerinden eğitilir. Model, müşteri sorularına uygun yanıtlar üretmek için optimize edilir. Dil modeli, GPT-2 gibi yapay zeka dil modelleri kullanılarak eğitilebilir.\n",
        "\n",
        "Müşteri Memnuniyeti Değerlendirmesi:\n",
        "Modelin yanıtları müşteri memnuniyetini değerlendirmek amacıyla KMeans kümeleme algoritması ile sınıflandırılır. Bu algoritma, müşteri memnuniyetini değerlendirerek modelin çıkışlarının müşteri memnuniyetine uygun olup olmadığını analiz eder.\n",
        "\n",
        "Geri Bildirim Döngüsü ve İyileştirme:\n",
        "Modelin performansı, müşteri memnuniyeti değerlendirmelerine göre sürekli izlenir ve iyileştirmeler yapılır. Bu döngü, modelin doğru ve anlamlı yanıtlar üretmesini sağlamak için önemlidir.\n",
        "\n",
        "Bu çözüm yöntemi, müşteri hizmetleri botunun müşteri sorularına doğru ve anlamlı yanıtlar üretmesini sağlamak ve müşteri memnuniyetini değerlendirmek için çeşitli yapay zeka ve veri analitiği tekniklerini bir araya getirir."
      ],
      "metadata": {
        "id": "aAXG9gGrPX1m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.Sonuç ve Değerlendirme:\n",
        "\n",
        "Bu projede, müşteri hizmetleri botu için GPT-2 dil modeli eğitilmiş ve müşteri memnuniyeti değerlendirmesi için KMeans kümeleme algoritması kullanılmıştır. Bu çözüm yöntemi, müşteri sorularına ve yanıtlarına dayalı olarak doğru ve anlamlı yanıtlar üretmek, aynı zamanda müşteri memnuniyetini değerlendirmek üzere geliştirilmiştir.\n",
        "\n",
        "Dil Modeli Eğitim ve Optimizasyonu:\n",
        "GPT-2 modelinin eğitim süreci başarılı bir şekilde tamamlanmış ve müşteri soruları ile yanıtları üzerinden optimize edilmiştir. Model, müşteri sorularına yönelik anlamlı ve doğru yanıtlar üretmek için gereken performansı sergilemiştir.\n",
        "\n",
        "Veri Ön İşleme ve Analiz:\n",
        "Müşteri soruları ve yanıtları üzerinde yapılan veri ön işleme işlemleri, metin temizleme, tokenizasyon ve padleme gibi adımlarla gerçekleştirilmiştir. Bu işlemler, modelin doğru şekilde işleyebilmesi ve anlamlı sonuçlar üretebilmesi için önemlidir.\n",
        "\n",
        "Müşteri Memnuniyeti Değerlendirmesi:\n",
        "KMeans kümeleme algoritması, modelin yanıtlarının müşteri memnuniyeti ile uyumlu olup olmadığını değerlendirmek için kullanılmıştır. Bu sayede modelin müşteri geri bildirimlerine olan duyarlılığı artırılmış ve müşteri memnuniyetine yönelik iyileştirmeler önerilmiştir.\n",
        "\n",
        "Geri Bildirim Döngüsü ve İyileştirme:\n",
        "Modelin performansı, müşteri memnuniyeti değerlendirmeleri ile izlenmiş ve gerekli iyileştirmeler sürekli olarak uygulanmıştır. Bu döngü, modelin müşteri ihtiyaçlarına daha iyi yanıt vermesini sağlamıştır."
      ],
      "metadata": {
        "id": "h8ZRuCiZP6Gk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5.KULLANILAN KAYNAKLAR\n",
        "\n",
        "Bu projede kullanılan bazı kaynaklar ve kütüphaneler şunlardır:\n",
        "\n",
        "Hugging Face Transformers Kütüphanesi:\n",
        "Hugging Face Transformers kütüphanesi, GPT-2 gibi büyük dil modellerinin eğitimi ve kullanımı için yaygın olarak kullanılan bir araçtır. Bu kütüphane, dil modellerinin ön işlem yapma, eğitme ve finetune etme süreçlerini kolaylaştırır.\n",
        "\n",
        "KMeans Kümeleme Algoritması:\n",
        "Müşteri memnuniyeti değerlendirmesi için KMeans kümeleme algoritması kullanılmıştır. Bu algoritma, müşteri geri bildirimlerinin analiz edilmesine ve sınıflandırılmasına yardımcı olur.\n",
        "\n",
        "Pandas ve Numpy Kütüphaneleri:\n",
        "Veri ön işleme işlemlerinde ve veri analizi sürecinde Pandas ve Numpy gibi veri bilim kütüphanelerinden yararlanılmıştır.\n",
        "\n",
        "PyTorch veya TensorFlow:\n",
        "GPT-2 modelinin eğitimi ve finetune süreci için PyTorch veya TensorFlow gibi derin öğrenme kütüphaneleri kullanılmıştır.\n",
        "\n",
        "Scikit-Learn:\n",
        "Müşteri memnuniyeti değerlendirmesi ve model değerlendirmesi için Scikit-Learn kütüphanesi kullanılmıştır. Özellikle KMeans algoritmasının yanı sıra, diğer model performansı değerlendirme metrikleri de bu kütüphanede bulunabilir."
      ],
      "metadata": {
        "id": "FeR1RbkmTfHF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "mguHrVk34VG8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer, AdamW\n",
        "from sklearn.cluster import KMeans\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    'soru': [\n",
        "        \"İade politikası nedir?\",\n",
        "        \"Siparişim nerede?\",\n",
        "        \"Uluslararası gönderim yapıyor musunuz?\",\n",
        "        \"Siparişimi değiştirebilir miyim?\",\n",
        "        \"Hangi ödeme yöntemlerini kabul ediyorsunuz?\"\n",
        "    ],\n",
        "    'cevap': [\n",
        "        \"İade politikamız 30 gündür.\",\n",
        "        \"Siparişinizi e-posta ile gönderdiğimiz takip numarasıyla takip edebilirsiniz.\",\n",
        "        \"Evet, uluslararası gönderim yapıyoruz.\",\n",
        "        \"Evet, siparişinizi yerleştirildikten 24 saat içinde değiştirebilirsiniz.\",\n",
        "        \"Kredi kartı ve PayPal'ı kabul ediyoruz.\"\n",
        "    ],\n",
        "    'musteri_memnuniyeti': [\n",
        "        \"memnun\", \"memnun\", \"memnun değil\", \"memnun\", \"memnun\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n"
      ],
      "metadata": {
        "id": "9ngjuY284WBi"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"gpt2\"\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "tokenizer.pad_token = tokenizer.eos_token  # eos_token'ı pad_token olarak ayarlama\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "model.resize_token_embeddings(len(tokenizer))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQV4n5de4dn0",
        "outputId": "d8f65647-f73f-4603-bcb4-ee693ef5a85c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(50257, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class QADataset(Dataset):\n",
        "    def __init__(self, questions, answers, tokenizer, max_length=50):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "        self.questions = questions\n",
        "        self.answers = answers\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.questions)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        question = self.questions[idx]\n",
        "        answer = self.answers[idx]\n",
        "        input_encodings = self.tokenizer(question, truncation=True, padding='max_length', max_length=self.max_length, return_tensors=\"pt\")\n",
        "        target_encodings = self.tokenizer(answer, truncation=True, padding='max_length', max_length=self.max_length, return_tensors=\"pt\")\n",
        "        labels = target_encodings['input_ids']\n",
        "        labels[labels == self.tokenizer.pad_token_id] = -100  # Ignore padding token in labels\n",
        "\n",
        "        return {\n",
        "            'input_ids': input_encodings['input_ids'].squeeze(),\n",
        "            'attention_mask': input_encodings['attention_mask'].squeeze(),\n",
        "            'labels': labels.squeeze()\n",
        "        }\n",
        "\n",
        "dataset = QADataset(df['soru'].tolist(), df['cevap'].tolist(), tokenizer)\n",
        "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)  # Batch size'ı küçülttük"
      ],
      "metadata": {
        "id": "SjvuEkKZ4eVC"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fine_tune_model(dataloader, model, epochs=1):\n",
        "    optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for batch in dataloader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'], labels=batch['labels'])\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs} completed with average loss: {total_loss / len(dataloader)}\")\n",
        "\n",
        "fine_tune_model(dataloader, model, epochs=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "os4U55RY4hXR",
        "outputId": "77ebe84a-0330-495d-e60e-1bf4f76b3688"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3 completed with average loss: 8.306418800354004\n",
            "Epoch 2/3 completed with average loss: 5.743565082550049\n",
            "Epoch 3/3 completed with average loss: 5.218015909194946\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feedback_map = {\"memnun\": 1, \"memnun değil\": 0}\n",
        "feedbacks = df['musteri_memnuniyeti'].map(feedback_map).values.reshape(-1, 1)\n",
        "kmeans = KMeans(n_clusters=2, random_state=42)\n",
        "df['memnuniyet_kumesi'] = kmeans.fit_predict(feedbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XGEVa6n4lI6",
        "outputId": "e9801e6a-2155-4159-8202-21698f874408"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_bot(question, tokenizer, model):\n",
        "    model.eval()\n",
        "    inputs = tokenizer.encode(question, return_tensors='pt', truncation=True, padding='max_length', max_length=50)\n",
        "    outputs = model.generate(inputs, max_length=50, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id, max_new_tokens=100)\n",
        "    answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return answer\n",
        "\n",
        "def handle_customer_question(question, feedback, tokenizer, model, df):\n",
        "    answer = ask_bot(question, tokenizer, model)\n",
        "    new_data = {'soru': question, 'cevap': answer, 'musteri_memnuniyeti': feedback}\n",
        "    df = pd.concat([df, pd.DataFrame([new_data])], ignore_index=True)\n",
        "    # Modeli yeniden eğitme\n",
        "    dataset = QADataset(df['soru'].tolist(), df['cevap'].tolist(), tokenizer)\n",
        "    dataloader = DataLoader(dataset, batch_size=1, shuffle=True)  # Batch size'ı küçülttük\n",
        "    fine_tune_model(dataloader, model, epochs=1)\n",
        "    # Müşteri memnuniyetini yeniden kümelendirme\n",
        "    feedbacks = df['musteri_memnuniyeti'].map(feedback_map).values.reshape(-1, 1)\n",
        "    df['memnuniyet_kumesi'] = kmeans.fit_predict(feedbacks)\n",
        "    return answer\n",
        "\n",
        "# Test etme\n",
        "test_question = \"Siparişimi nasıl iptal edebilirim?\"\n",
        "test_feedback = \"memnun\"\n",
        "response = handle_customer_question(test_question, test_feedback, tokenizer, model, df)\n",
        "print(f\"Yanıt: {response}\")\n",
        "print(f\"Güncellenmiş DataFrame: {df}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FN50hnhn4lke",
        "outputId": "e33e481a-36d1-4339-9c16-1b315d5d6844"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=100) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1 completed with average loss: 5.6591663757960005\n",
            "Yanıt: Siparişimi nasıl iptal edebilirim?A new study finds that the number of people who have been diagnosed with autism has increased by more than 50 per cent in the past decade.\n",
            "\n",
            "The study, published in the journal Pediatrics, found that the number of people diagnosed with autism has increased by more than 50 per cent in the past decade.\n",
            "\n",
            "The study, conducted by researchers at the University of California, San Francisco, found that the number of people diagnosed with autism has increased by more than 50 per cent in the past decade.\n",
            "Güncellenmiş DataFrame:                                           soru  \\\n",
            "0                       İade politikası nedir?   \n",
            "1                            Siparişim nerede?   \n",
            "2       Uluslararası gönderim yapıyor musunuz?   \n",
            "3             Siparişimi değiştirebilir miyim?   \n",
            "4  Hangi ödeme yöntemlerini kabul ediyorsunuz?   \n",
            "\n",
            "                                               cevap musteri_memnuniyeti  \\\n",
            "0                        İade politikamız 30 gündür.              memnun   \n",
            "1  Siparişinizi e-posta ile gönderdiğimiz takip n...              memnun   \n",
            "2             Evet, uluslararası gönderim yapıyoruz.        memnun değil   \n",
            "3  Evet, siparişinizi yerleştirildikten 24 saat i...              memnun   \n",
            "4            Kredi kartı ve PayPal'ı kabul ediyoruz.              memnun   \n",
            "\n",
            "   memnuniyet_kumesi  \n",
            "0                  0  \n",
            "1                  0  \n",
            "2                  1  \n",
            "3                  0  \n",
            "4                  0  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}